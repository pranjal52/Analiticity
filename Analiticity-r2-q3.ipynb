{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Election season is like party time at the casino, all Bellagio like fireworks and Swarovski studded promises and the sounds of poker chips stacking Up and Down.\n",
    "\n",
    "Currently India is also headed for a long and critical election season that span over five states,just as many weeks and 160 million voters. Many strategies are used by politicians to lure voters.Political advertising is one of them, used by candidates to reach and influence voters. It can include several different mediums and span several months over the course of a political campaign.Large amount is spend by politicians on such advertisings.\n",
    "\n",
    "Given here is data of total amount spend by different politicians over advertising all over the country in previous elections, along with different factors on which these expense depends like total time duration of compaigning,total no of hoardings,sizes of flexes,newspaper advertisement etc(some values have been normalised).\n",
    "\n",
    "Build a model with the help of training data with total expenditure as the goal field and predict the total expenditures for the given test data.\n",
    "\n",
    "The Training and Test Data can be downloaded from https://drive.google.com/drive/folders/0B5ecohWfA0rueFZwUF9qbURXQU0\n",
    "\n",
    "Input Format\n",
    "\n",
    "Sr No.\n",
    "F1 - F16 - different factors\n",
    "Total expenditures: total amount(in thousands) spent on advertising\n",
    "Output Format\n",
    "\n",
    "Submit the predicted value of total expenditures by serial number. If k1,k2,k3 are the values corresponding to the serial number 1,2,3. Output is \n",
    "k1 \n",
    "k2\n",
    "k3 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.67734917430077"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df=pd.read_excel(\"C:\\\\Users\\\\hi\\\\Desktop\\\\Analiticity\\\\Round 2\\\\Training_Election_Extravaganza.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1=df[df['F1'] < 80000000]\n",
    "df1=df1[(df1['F2'] > 0.25) & (df1['F2'] < 0.9)]\n",
    "df1=df1[df1['Total Expenditure'] < 30]\n",
    "\n",
    "df1.drop([825,2343,10417, 11128, 13590, 13702, 17166], inplace=True)\n",
    "df1.dropna(inplace=True,axis=1)\n",
    "#from scipy import stats\n",
    "#df1[(np.abs(stats.zscore(df1)) > 2.5).all(axis=1)]\n",
    "#df=df[(df['F3'] > 0.5) & (df['Total Expenditure'] > 5)]\n",
    "\n",
    "list1 = (df['F3'] - df['F3'].mean())/(df['F3'].max() - df['F3'].min())\n",
    "#plt.plot(df1['F3'], df1['Total Expenditure'],\"o\")\n",
    "df1['F3.1']=list1\n",
    "\n",
    "list2 = (df['F7'] - df['F7'].mean())/df['F7'].std()\n",
    "\n",
    "\n",
    "df1_norm=df1\n",
    "\n",
    "df1_norm['F3'] = ((df1['F3'] - df1['F3'].mean()) / df1['F3'].std())\n",
    "\n",
    "\n",
    "df1_norm['F4']= np.log1p(df1_norm['F4'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#np_scaled = min_max_scaler.fit_transform(df['F9'].reshape(-1,1))\n",
    "#df1_norm['F9'] = pd.DataFrame(np_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np_scaled = min_max_scaler.fit_transform(df['F5'].reshape(-1,1))\n",
    "df1_norm['F5'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df['F8'].reshape(-1,1))\n",
    "df1_norm['F8'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df['F10'].reshape(-1,1))\n",
    "df1_norm['F10'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df['F11'].reshape(-1,1))\n",
    "df1_norm['F11'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df['F12'].reshape(-1,1))\n",
    "df1_norm['F12'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df['F13'].reshape(-1,1))\n",
    "df1_norm['F13'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df['F14'].reshape(-1,1))\n",
    "df1_norm['F14'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df['F15'].reshape(-1,1))\n",
    "df1_norm['F15'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df['F16'].reshape(-1,1))\n",
    "df1_norm['F16'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "\n",
    "#df1_norm['F9'] = ((df1['F9'] - df1['F9'].mean()) / df1['F9'].std())\n",
    "\n",
    "\n",
    "#df1_norm['F11']=np.log1p(df1_norm['F11'])\n",
    "\n",
    "list1=df1_norm['F12']\n",
    "\n",
    "plt.hist(list1, bins=500)\n",
    "plt.xlim(0,1)\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "#df['']\n",
    "#df['Total Expenditure'].max()\n",
    "#df['F3'].max()\n",
    "#df1[df1['Total Expenditure'] < 0]\n",
    "\n",
    "#df1[(df1['F3'] > 0.1) & (df1['Total Expenditure'] > 12.5) & (df1['F3'] < 0.3)].index\n",
    "\n",
    "df1_norm=df1_norm[df1_norm['F1'] < 80000000]\n",
    "#df1_norm=df1_norm[(df1_norm['F2'] > 0.25) & (df1_norm['F2'] < 0.9)]\n",
    "df1_norm=df1_norm[df1_norm['Total Expenditure'] < 30]\n",
    "#df1_norm.drop([825,2343,10417, 11128, 13590, 13702, 17166], inplace=True, axis=0)\n",
    "\n",
    "\n",
    "keys=['F1', 'F2', 'F3','F4','F5', 'F7', 'F8', 'F9', 'F10', 'F11'\n",
    "       , 'F12', 'F13','F14', 'F15', 'F16']\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1_norm[keys], df1_norm['Total Expenditure'], test_size=0.2, random_state=1000)\n",
    "\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "rmse=np.sqrt(np.sum((regr.predict(X_test) - y_test)**2))\n",
    "rmse\n",
    "#list1[list1 > 0.9]\n",
    "#df1.corr()['Total Expenditure']\n",
    "#df1.max() - df1.min()\n",
    "#df1_norm['F4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e31d38390>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t=pd.read_excel(\"C:\\\\Users\\\\hi\\\\Desktop\\\\Analiticity\\\\Round 2\\\\Test_Election_Extravaganza.xlsx\")\n",
    "#rmse_t=np.sqrt(np.sum((regr.predict(df_t.drop('Sr. no', axis=1)) - df_t)**2))\n",
    "#rmse\n",
    "df_t_norm=df_t\n",
    "#df_t_norm['F3'] = (df_t['F3'] - df_t['F3'].mean())/df_t['F3'].std()\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n",
    "\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F4'].reshape(-1,1))\n",
    "df_t_norm['F4'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F5'].reshape(-1,1))\n",
    "df_t_norm['F5'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F8'].reshape(-1,1))\n",
    "df_t_norm['F8'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F10'].reshape(-1,1))\n",
    "df_t_norm['F10'] = pd.DataFrame(np_scaled)\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F11'].reshape(-1,1))\n",
    "df_t_norm['F11'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F12'].reshape(-1,1))\n",
    "df_t_norm['F12'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F13'].reshape(-1,1))\n",
    "df_t_norm['F13'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F14'].reshape(-1,1))\n",
    "df_t_norm['F14'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F15'].reshape(-1,1))\n",
    "df_t_norm['F15'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "np_scaled = min_max_scaler.fit_transform(df_t_norm['F16'].reshape(-1,1))\n",
    "df_t_norm['F16'] = np.log1p(pd.DataFrame(np_scaled))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_t['Total Expenditure']=regr.predict(df_t_norm.drop(['Sr. no', 'F6'], axis=1))\n",
    "#df_t['Total Expenditure'].to_csv('out.csv', index=False)\n",
    "df_t['mean']=np.mean(df_t['Total Expenditure'])\n",
    "df_t['ones']=1\n",
    "df_t[df_t['Total Expenditure'] <0] = df_t['Total Expenditure'].mean()\n",
    "#df_t[df_t['Total Expenditure'] >5] = 4.5\n",
    "\n",
    "df_t['Total Expenditure'].to_csv('out33.csv', index=False)\n",
    "plt.plot(df_t['F3'], df_t['Total Expenditure'],\"o\")\n",
    "#plot.show()S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
